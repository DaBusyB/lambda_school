#+TITLE: 13: Data Structures II
#+AUTHOR: Andrew Jarrett
#+EMAIL: ahrjarrett@gmail.com
#+OPTIONS: num:nil

* Todos

* Pre-Class Research

As of Sunday night, so far I've completed the homework for =Tree= and have 4 out of 5 tests passing for =BinarySearchTree=.

** Breadth-First BST Traversal

Where I first got stuck is breadth-first traversal of a tree. [[https://www.cs.bu.edu/teaching/c/tree/breadth-first/][This is a good article by Boston U about breadth-first traversal]].

*** Who Cares?

This is actually an important problem to solve. For example, org-mode relies on breadth-first traversal to determine the "rank" of a particular level of nesting. 

Breadth-first search is useful when "level" matters, for example, in this document, if I wanted to see all nodes that are siblings of this node, I hit =SHIFT-TAB=, and every node that is child to this node (level 2 deep) and child of this node's siblings will collapse. In order to do this, we only need to traverse the document of nodes 3 levels deep: the root node, which can be thought of as the document itself, all =<h1>= or text indented with 1 star, and the children of all those with 1 star (or, every 2-star).

Or, to use a cool example from the article:

#+BEGIN_SRC
Another time when breadth-first traversal comes in handy is with game trees. Suppose 
we have a tree for a game of chess. In other words, levels of the tree  alternately 
represent possible moves by you, and then by your opponent, and then by you...

               current state of game
        /                |             \
   move                move     ...   move    <-- your moves
   queen's             king's         queen
   bishop              knight
 /     |    \         /    |   \        |
move  move   ...   move  move  ...     ...    <-- opponent's moves
king  queen's      king  king's
      rook               knight
        |                  |
        .                  .
        .                  .
        .                  .

You have exactly 1 minute to decide on a move. Now, which would be a better use 
of that time: exploring the branch where you "move your queen's bishop" to its 
fullest extent (go deep) or explore each of your possible next move first, 
and then your opponent's responses (breadth-first).
#+END_SRC

*** How we can make it work:

We can use another data structure: [[https://github.com/ahrjarrett/Data-Structures-II/blob/77bb01e41b8fe7f4b041e049f33810aed3065e7e/src/queue-helper.js][a Queue]].

#+BEGIN_SRC js
  class Queue {
      constructor() {
          this.storage = [];
      }

      enqueue(x) {
          this.storage.push(x);
      }

      dequeue() {
          return this.storage.shift();
      }

      isEmpty() {
          return this.storage.length === 0;
      }
  }
#+END_SRC

From the Boston University article:

#+BEGIN_SRC
What we'll do is store each element in the tree in a data structure and 
process (or visit) them as we remove them from the data structure.

We can best determine what data structure we need by looking at an example:

   f
 /   \
a     h
 \
  d

When we are at element f, that is the only time we have access to 
its 2 immediate children, a and h. So, when we are at f, we'd better 
put its children in the data structure. Obviously then, f must have 
been in the data structure before them (i.e., first), since we'd have 
put f in when we were at f's parent.
#+END_SRC


*** Roadblocks

At first I thought we could simple add a =this.storage= property on the BST and, in the =insert= method, simply enqueue every element as we insert it. But on second thought, this doesn't solve the problem, because the order that this queue holds is dependent upon the order that they were inserted into the tree, which doesn't necessarily have any meaning outside of creating a history of the data structure.

Instead, we will use queue in a more interesting way.

*** Talking through a possible solution

First, we can put the root node inside of the queue as the first and only value (for now).

Then, we can execute a =while= loop to check if the queue is empty; it is not, so we will dequeue the first (and right now, only) node and pass its value to the callback.

Now, still inside the while loop, we will enqueue the node's left and the node's right.

That's it for our while loop; now, the queue will have 2 elements in it (the former node's left and right values). We will continue to dequeue a node and enqueue its children to be passed into the callback later (but not before its sibling's value is passed to the function, and the sibling's children enqueued). When the final node is dequeued and its value is passed to the callback function, we exit the =while= loop.


*** Walking through the "breakpoints"

Lambda School's test for breadth first traversal creates a tree that looks like this:

#+BEGIN_SRC 
                 5
              /     \
            3        10
             \      /   \
              4    9    11
#+END_SRC

That means our order should look like this: [5, 3, 10, 4, 9, 11]

When we execute, first we put the root node into the queue and call the callback on 5. Here's what happens:

#+BEGIN_SRC
1. Queue: [5]

                *5*              fn(5)
              /     \            new queue: [3 10]
            3        10          order: [5]
             \      /   \
              4    9    11


2. Queue: [3 10]

                 5               fn(3)
              /     \            new queue: [10 4]
           *3*       10          order: [5 3]
             \      /   \
              4    9    11


3. Queue: [10 4]

                 5               fn(10)
              /     \            new queue: [4 9 11]
            3       *10*         order: [5 3 10]
             \      /   \
              4    9    11


4. Queue: [4 9 11]

                 5               fn(4)
              /     \            new queue: [9 11]
            3        10          order: [5 3 10 4]
             \      /   \
             *4*   9    11


5. Queue: [9 11]

                 5               fn(9)
              /     \            new queue: [11]
            3        10          order: [5 2 10 4 9]
             \      /   \
              4   *9*   11


6. Queue: [11]

                 5               fn(11)
              /     \            new queue: []
            3        10          order: [5 2 10 4 9 11]
             \      /   \
              4    9    *11*

#+END_SRC
* Pre-Class Video Notes

[[https://www.youtube.com/watch?v=FBlxViiYm9A][This is the video of Sean talking about DS-II]] that we watched before class started. And here are my notes on that video!

** Trees

When you look at a tree, you can look at one branch and see that it is basically nothing more than a LinkedList. Note that one node can be a part of multiple LinkedLists.

Trees have a few important use cases, but they're not as useful as other data structures in and of themselves. However, they are well-suited as a foundation for building more complex data structures.

Besides BSTs, there are also prefix trees and B-trees, along with a host of other implementations.

- Think of trees as being a much wider, fatter LL
- Each parent node holds a reference to all of its children nodes, just like how each LL node holds a reference to the next node in the LL
- Best suited for representing large, complex hierarchies

** Binary Search Trees

In a BST, each parent can have /at most/ 2 children. It can also have 1 child, or no children (in which case we call the node a /leaf/).

Sorting happens upon insertion; nodes on the left are lesser than their parent(s), and the nodes on the right are greater than their parent(s).

Because they are sorted from the outset, it makes them very efficient at searching for a particular node, hence the name.

Instead of iterating through the entire tree, every time we make a comparison, we prune off half the tree and move closer to finding our value. This procedure has an =O(log(n)= time complexity, as opposed to linear.

*** Logarithmic Time Complexity

Although slow for very small input sizes, =O(log(n))= quickly becomes faster than linear time.

So as the input size increases, computations that are =O(log(n))= remain extremely efficient.

If we had a BST containing 1,000,000 nodes, how many steps would that take to perform?

#+BEGIN_SRC
  1000000 / 2 / 2 / 2 ... = 1?
#+END_SRC

In this case, the number of steps required to find the value, at worst, is about 20. This assumes a perfectly balanced tree, of course.

*** 2 Types of Searching Algorithms

There are 2 main categories of searching algorithms for trees:

**** 1: Depth-First Search

Traverse all the way down, then back up and across to find a particular node.

**** 2: Breadth-First Search

First traverse the node's immediately children, then traverse the grandchildren, then the great-grandchildren, and so on.

** Graphs

Graphs have been gaining traction in the past decade or so.

One of the most common use cases for graphs is a network -- i.e., a social network like Facebook.

Graphs may seem structurally similar to trees, but the purpose of a graph is representing connections between nodes. These connections, or *edges*, are what is important.

The nodes, or /vertices/, are the points where lines connect, and the lines as already said are the /edges/.

There are two main flavors of graphs:

*** Directed Graphs

Arrows, in a directed graph, represent directionality. If we were modeling a map, and the vertices are cities, then the edges could represent direction of traffic.

Note that this traffic can be one way.

*** Undirected Graphs

When there isn't any inherent directionality involved or implied by an edge (for example, when two people are friends on Facebook, that connection is reciprocal and bi-directional), then we would use an undirected graph to model the problem.

**** Representing connections

This is an example of how we might represent connections, or edges, between vertices:

#+BEGIN_SRC js
  const graphNode1 = {
      edges: ['graphNode2'],
      ...
  }

  const graphNode2 = {
      edges: ['graphNode1'],
      ...
  }
#+END_SRC

